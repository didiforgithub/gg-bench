prompt: |
  <GameDescription>

  Given this description, write a gym environment that implements this single-player puzzle game. Use gymnasium's API to define the environment. The action_space of the environment should be a Discrete space, use spaces.Discrete to define the action_space. The observation_space should be a Box space, use spaces.Box to define it. 
  
  The reward system should be:
  - +100 if the player successfully solves the puzzle
  - -1 for each step taken (to encourage efficiency)
  - -50 if the player reaches a failure state (if applicable)
  - 0 for regular valid moves that don't end the game

  The environment should be designed for single-agent reinforcement learning.

  The environment should have the following methods:
  - `reset()`: Reset the environment to its initial state. Returns observation, info (dict).
  - `step(action)`: Take a step in the environment. Returns observation, reward, terminated, truncated, info (dict).
  - `render()`: Return a visual representation of the environment state as a string.
  - `valid_moves()`: Return a list of integers of valid moves as indices of the action_space.
  - `is_solved()`: Return True if the puzzle is solved, False otherwise.

  Here is an example of how to define the environment:
  ```python
  import numpy as np
  import gymnasium as gym
  from gymnasium import spaces


  class SokobanEnv(gym.Env):
      def __init__(self, level_size=5):
          super(SokobanEnv, self).__init__()
          
          self.level_size = level_size
          
          # Define action space: 0=up, 1=down, 2=left, 3=right
          self.action_space = spaces.Discrete(4)
          
          # Define observation space (flattened grid)
          # 0=empty, 1=wall, 2=box, 3=target, 4=player, 5=box_on_target
          self.observation_space = spaces.Box(
              low=0, high=5, shape=(level_size * level_size,), dtype=np.float32
          )
          
          self.reset()

      def reset(self, seed=None, options=None):
          super().reset(seed=seed)
          
          # Initialize simple level
          self.grid = np.zeros((self.level_size, self.level_size), dtype=np.float32)
          
          # Add walls around border
          self.grid[0, :] = 1
          self.grid[-1, :] = 1
          self.grid[:, 0] = 1
          self.grid[:, -1] = 1
          
          # Add player, box, and target
          self.player_pos = [1, 1]
          self.grid[1, 1] = 4  # player
          self.grid[2, 2] = 2  # box
          self.grid[3, 3] = 3  # target
          
          self.done = False
          return self.grid.flatten(), {}

      def step(self, action):
          if self.done:
              return self.grid.flatten(), 0, True, False, {}
          
          # Define movement directions
          moves = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # up, down, left, right
          dy, dx = moves[action]
          
          new_y, new_x = self.player_pos[0] + dy, self.player_pos[1] + dx
          
          # Check bounds and walls
          if (new_y < 0 or new_y >= self.level_size or 
              new_x < 0 or new_x >= self.level_size or 
              self.grid[new_y, new_x] == 1):
              return self.grid.flatten(), -1, False, False, {}
          
          # Move player
          self.grid[self.player_pos[0], self.player_pos[1]] = 0
          self.player_pos = [new_y, new_x]
          self.grid[new_y, new_x] = 4
          
          # Check if solved
          if self.is_solved():
              self.done = True
              return self.grid.flatten(), 100, True, False, {}
          
          return self.grid.flatten(), -1, False, False, {}

      def render(self):
          symbols = {0: ' ', 1: '#', 2: '$', 3: '.', 4: '@', 5: '*'}
          result = ""
          for row in self.grid:
              for cell in row:
                  result += symbols[int(cell)]
              result += "\n"
          return result

      def valid_moves(self):
          return list(range(4))  # All directions always available to try

      def is_solved(self):
          # Check if box is on target
          return np.any((self.grid == 2) & (self.grid == 3))  # This is simplified
  ```

  Call the environment `CustomEnv`. Do not include any code that creates the gym environment or tests it. Make sure the environment is fully functional, requires no modifications and adheres to the requirements specified in the prompt. Do not include any placeholder functions or TODOs in the code.
model: o3
max_completion_tokens: 8192
num_games: 1
